{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "#### 1. 使用原始数据，未做regularize，使用2层same padding卷积，步长为2的池化，两个全连接层，88.7%的准确率\n",
    "#### 2. 和1中的所有操作相同的，但是做了regularize，准确率88.84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_description = {0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress',\n",
    "                        4: 'Coat', 5: 'Sandal', 6: 'Shirt',\n",
    "                       7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot',\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000])\n",
      "tensor(9)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# path_to_datasets = '/home/lor/Datasets/FashionMNIST/FashionMNIST/processed/training.pt'\n",
    "path_to_datasets = 'E:/data/FashionMNIST/FashionMNIST/processed/training.pt'\n",
    "samples = torch.load(path_to_datasets)\n",
    "features = samples[0]\n",
    "targets = samples[1]\n",
    "print(features.shape, targets.shape)\n",
    "print(targets.max())\n",
    "print(targets.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.array(features[3]), cmap='gray')\n",
    "ax.set_title(label_to_description[targets.storage()[3]])\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.array(features[4]), cmap='gray')\n",
    "ax.set_title(label_to_description[targets.storage()[4]])\n",
    "plt.show()\n",
    "# plt.title(label_to_description[targets.storage()[3]])\n",
    "# label_to_description[targets.storage()[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.targets[idx]\n",
    "        feature = self.features[idx].unsqueeze(0).float()\n",
    "        feature = (feature - torch.min(feature)) / (torch.max(feature) - torch.min(feature))\n",
    "        return (target, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UserDataset(features, targets)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 9, 2, 2, 8, 9, 9, 4, 6, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_iter = next(iter(train_dataloader))\n",
    "one_iter[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(one_iter[1][i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    ax.set_title(label_to_description[one_iter[0].storage()[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(1, 16, kernel_size=(5, 5), stride=1, padding=2),\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(16, 24, kernel_size=(5, 5), stride=1, padding=2),\n",
    "                        nn.BatchNorm2d(24),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 24, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        res = self.fc2(out)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Network()\n",
    "net.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3)\n",
    "\n",
    "total_step = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/6000], Loss: 1.8791\n",
      "Epoch [1/10], Step [200/6000], Loss: 1.5186\n",
      "Epoch [1/10], Step [300/6000], Loss: 1.0306\n",
      "Epoch [1/10], Step [400/6000], Loss: 1.3205\n",
      "Epoch [1/10], Step [500/6000], Loss: 0.8384\n",
      "Epoch [1/10], Step [600/6000], Loss: 0.8140\n",
      "Epoch [1/10], Step [700/6000], Loss: 1.1051\n",
      "Epoch [1/10], Step [800/6000], Loss: 0.6479\n",
      "Epoch [1/10], Step [900/6000], Loss: 0.6861\n",
      "Epoch [1/10], Step [1000/6000], Loss: 0.3241\n",
      "Epoch [1/10], Step [1100/6000], Loss: 1.0750\n",
      "Epoch [1/10], Step [1200/6000], Loss: 0.8653\n",
      "Epoch [1/10], Step [1300/6000], Loss: 0.5152\n",
      "Epoch [1/10], Step [1400/6000], Loss: 0.6459\n",
      "Epoch [1/10], Step [1500/6000], Loss: 0.8832\n",
      "Epoch [1/10], Step [1600/6000], Loss: 0.6115\n",
      "Epoch [1/10], Step [1700/6000], Loss: 0.7726\n",
      "Epoch [1/10], Step [1800/6000], Loss: 0.7592\n",
      "Epoch [1/10], Step [1900/6000], Loss: 0.4743\n",
      "Epoch [1/10], Step [2000/6000], Loss: 0.8996\n",
      "Epoch [1/10], Step [2100/6000], Loss: 0.4108\n",
      "Epoch [1/10], Step [2200/6000], Loss: 1.3470\n",
      "Epoch [1/10], Step [2300/6000], Loss: 0.6943\n",
      "Epoch [1/10], Step [2400/6000], Loss: 0.4590\n",
      "Epoch [1/10], Step [2500/6000], Loss: 0.4654\n",
      "Epoch [1/10], Step [2600/6000], Loss: 0.4561\n",
      "Epoch [1/10], Step [2700/6000], Loss: 0.6097\n",
      "Epoch [1/10], Step [2800/6000], Loss: 0.4298\n",
      "Epoch [1/10], Step [2900/6000], Loss: 0.6816\n",
      "Epoch [1/10], Step [3000/6000], Loss: 0.3127\n",
      "Epoch [1/10], Step [3100/6000], Loss: 0.2633\n",
      "Epoch [1/10], Step [3200/6000], Loss: 0.3197\n",
      "Epoch [1/10], Step [3300/6000], Loss: 0.6220\n",
      "Epoch [1/10], Step [3400/6000], Loss: 0.4548\n",
      "Epoch [1/10], Step [3500/6000], Loss: 0.6424\n",
      "Epoch [1/10], Step [3600/6000], Loss: 0.5427\n",
      "Epoch [1/10], Step [3700/6000], Loss: 0.4624\n",
      "Epoch [1/10], Step [3800/6000], Loss: 0.6175\n",
      "Epoch [1/10], Step [3900/6000], Loss: 0.9198\n",
      "Epoch [1/10], Step [4000/6000], Loss: 0.1723\n",
      "Epoch [1/10], Step [4100/6000], Loss: 0.2410\n",
      "Epoch [1/10], Step [4200/6000], Loss: 0.6988\n",
      "Epoch [1/10], Step [4300/6000], Loss: 0.4779\n",
      "Epoch [1/10], Step [4400/6000], Loss: 0.5183\n",
      "Epoch [1/10], Step [4500/6000], Loss: 0.3999\n",
      "Epoch [1/10], Step [4600/6000], Loss: 0.3589\n",
      "Epoch [1/10], Step [4700/6000], Loss: 0.6730\n",
      "Epoch [1/10], Step [4800/6000], Loss: 0.1973\n",
      "Epoch [1/10], Step [4900/6000], Loss: 0.6762\n",
      "Epoch [1/10], Step [5000/6000], Loss: 0.1417\n",
      "Epoch [1/10], Step [5100/6000], Loss: 0.7451\n",
      "Epoch [1/10], Step [5200/6000], Loss: 0.2441\n",
      "Epoch [1/10], Step [5300/6000], Loss: 0.2072\n",
      "Epoch [1/10], Step [5400/6000], Loss: 0.7193\n",
      "Epoch [1/10], Step [5500/6000], Loss: 0.1628\n",
      "Epoch [1/10], Step [5600/6000], Loss: 0.4364\n",
      "Epoch [1/10], Step [5700/6000], Loss: 0.3523\n",
      "Epoch [1/10], Step [5800/6000], Loss: 0.3759\n",
      "Epoch [1/10], Step [5900/6000], Loss: 0.6030\n",
      "Epoch [1/10], Step [6000/6000], Loss: 0.1669\n",
      "Epoch [2/10], Step [100/6000], Loss: 0.1547\n",
      "Epoch [2/10], Step [200/6000], Loss: 0.5146\n",
      "Epoch [2/10], Step [300/6000], Loss: 0.5722\n",
      "Epoch [2/10], Step [400/6000], Loss: 0.4013\n",
      "Epoch [2/10], Step [500/6000], Loss: 0.6849\n",
      "Epoch [2/10], Step [600/6000], Loss: 0.2888\n",
      "Epoch [2/10], Step [700/6000], Loss: 0.1515\n",
      "Epoch [2/10], Step [800/6000], Loss: 0.0576\n",
      "Epoch [2/10], Step [900/6000], Loss: 0.3322\n",
      "Epoch [2/10], Step [1000/6000], Loss: 0.4681\n",
      "Epoch [2/10], Step [1100/6000], Loss: 0.3914\n",
      "Epoch [2/10], Step [1200/6000], Loss: 0.3667\n",
      "Epoch [2/10], Step [1300/6000], Loss: 0.2860\n",
      "Epoch [2/10], Step [1400/6000], Loss: 0.7207\n",
      "Epoch [2/10], Step [1500/6000], Loss: 0.2444\n",
      "Epoch [2/10], Step [1600/6000], Loss: 0.4621\n",
      "Epoch [2/10], Step [1700/6000], Loss: 0.5756\n",
      "Epoch [2/10], Step [1800/6000], Loss: 0.3246\n",
      "Epoch [2/10], Step [1900/6000], Loss: 0.2349\n",
      "Epoch [2/10], Step [2000/6000], Loss: 0.6894\n",
      "Epoch [2/10], Step [2100/6000], Loss: 0.0626\n",
      "Epoch [2/10], Step [2200/6000], Loss: 0.2081\n",
      "Epoch [2/10], Step [2300/6000], Loss: 0.5927\n",
      "Epoch [2/10], Step [2400/6000], Loss: 0.3560\n",
      "Epoch [2/10], Step [2500/6000], Loss: 0.1115\n",
      "Epoch [2/10], Step [2600/6000], Loss: 0.3915\n",
      "Epoch [2/10], Step [2700/6000], Loss: 0.5338\n",
      "Epoch [2/10], Step [2800/6000], Loss: 0.5848\n",
      "Epoch [2/10], Step [2900/6000], Loss: 0.2046\n",
      "Epoch [2/10], Step [3000/6000], Loss: 0.0935\n",
      "Epoch [2/10], Step [3100/6000], Loss: 0.3867\n",
      "Epoch [2/10], Step [3200/6000], Loss: 0.3107\n",
      "Epoch [2/10], Step [3300/6000], Loss: 0.5676\n",
      "Epoch [2/10], Step [3400/6000], Loss: 0.4878\n",
      "Epoch [2/10], Step [3500/6000], Loss: 0.3900\n",
      "Epoch [2/10], Step [3600/6000], Loss: 0.2575\n",
      "Epoch [2/10], Step [3700/6000], Loss: 0.4642\n",
      "Epoch [2/10], Step [3800/6000], Loss: 0.7954\n",
      "Epoch [2/10], Step [3900/6000], Loss: 0.5495\n",
      "Epoch [2/10], Step [4000/6000], Loss: 0.5255\n",
      "Epoch [2/10], Step [4100/6000], Loss: 0.2518\n",
      "Epoch [2/10], Step [4200/6000], Loss: 0.0766\n",
      "Epoch [2/10], Step [4300/6000], Loss: 0.2724\n",
      "Epoch [2/10], Step [4400/6000], Loss: 0.7871\n",
      "Epoch [2/10], Step [4500/6000], Loss: 0.4781\n",
      "Epoch [2/10], Step [4600/6000], Loss: 0.4236\n",
      "Epoch [2/10], Step [4700/6000], Loss: 0.5645\n",
      "Epoch [2/10], Step [4800/6000], Loss: 0.4689\n",
      "Epoch [2/10], Step [4900/6000], Loss: 0.2032\n",
      "Epoch [2/10], Step [5000/6000], Loss: 0.2310\n",
      "Epoch [2/10], Step [5100/6000], Loss: 0.2840\n",
      "Epoch [2/10], Step [5200/6000], Loss: 0.2753\n",
      "Epoch [2/10], Step [5300/6000], Loss: 0.1152\n",
      "Epoch [2/10], Step [5400/6000], Loss: 0.2796\n",
      "Epoch [2/10], Step [5500/6000], Loss: 0.1772\n",
      "Epoch [2/10], Step [5600/6000], Loss: 0.4658\n",
      "Epoch [2/10], Step [5700/6000], Loss: 0.3099\n",
      "Epoch [2/10], Step [5800/6000], Loss: 0.2252\n",
      "Epoch [2/10], Step [5900/6000], Loss: 0.1471\n",
      "Epoch [2/10], Step [6000/6000], Loss: 0.1841\n",
      "Epoch [3/10], Step [100/6000], Loss: 0.5449\n",
      "Epoch [3/10], Step [200/6000], Loss: 0.3095\n",
      "Epoch [3/10], Step [300/6000], Loss: 0.3271\n",
      "Epoch [3/10], Step [400/6000], Loss: 0.2505\n",
      "Epoch [3/10], Step [500/6000], Loss: 0.5994\n",
      "Epoch [3/10], Step [600/6000], Loss: 0.5619\n",
      "Epoch [3/10], Step [700/6000], Loss: 0.2191\n",
      "Epoch [3/10], Step [800/6000], Loss: 0.1863\n",
      "Epoch [3/10], Step [900/6000], Loss: 0.2115\n",
      "Epoch [3/10], Step [1000/6000], Loss: 0.0578\n",
      "Epoch [3/10], Step [1100/6000], Loss: 0.1348\n",
      "Epoch [3/10], Step [1200/6000], Loss: 0.2253\n",
      "Epoch [3/10], Step [1300/6000], Loss: 0.8443\n",
      "Epoch [3/10], Step [1400/6000], Loss: 0.2248\n",
      "Epoch [3/10], Step [1500/6000], Loss: 0.1372\n",
      "Epoch [3/10], Step [1600/6000], Loss: 0.2507\n",
      "Epoch [3/10], Step [1700/6000], Loss: 0.3759\n",
      "Epoch [3/10], Step [1800/6000], Loss: 0.2704\n",
      "Epoch [3/10], Step [1900/6000], Loss: 0.4163\n",
      "Epoch [3/10], Step [2000/6000], Loss: 0.3306\n",
      "Epoch [3/10], Step [2100/6000], Loss: 0.1019\n",
      "Epoch [3/10], Step [2200/6000], Loss: 0.3282\n",
      "Epoch [3/10], Step [2300/6000], Loss: 0.2392\n",
      "Epoch [3/10], Step [2400/6000], Loss: 0.1327\n",
      "Epoch [3/10], Step [2500/6000], Loss: 0.1271\n",
      "Epoch [3/10], Step [2600/6000], Loss: 0.2381\n",
      "Epoch [3/10], Step [2700/6000], Loss: 0.3865\n",
      "Epoch [3/10], Step [2800/6000], Loss: 0.3507\n",
      "Epoch [3/10], Step [2900/6000], Loss: 0.8255\n",
      "Epoch [3/10], Step [3000/6000], Loss: 0.1943\n",
      "Epoch [3/10], Step [3100/6000], Loss: 0.3544\n",
      "Epoch [3/10], Step [3200/6000], Loss: 0.6802\n",
      "Epoch [3/10], Step [3300/6000], Loss: 0.3275\n",
      "Epoch [3/10], Step [3400/6000], Loss: 0.1661\n",
      "Epoch [3/10], Step [3500/6000], Loss: 0.0438\n",
      "Epoch [3/10], Step [3600/6000], Loss: 0.1301\n",
      "Epoch [3/10], Step [3700/6000], Loss: 0.0366\n",
      "Epoch [3/10], Step [3800/6000], Loss: 0.3572\n",
      "Epoch [3/10], Step [3900/6000], Loss: 0.1187\n",
      "Epoch [3/10], Step [4000/6000], Loss: 0.3425\n",
      "Epoch [3/10], Step [4100/6000], Loss: 0.3456\n",
      "Epoch [3/10], Step [4200/6000], Loss: 0.3156\n",
      "Epoch [3/10], Step [4300/6000], Loss: 0.4247\n",
      "Epoch [3/10], Step [4400/6000], Loss: 0.3380\n",
      "Epoch [3/10], Step [4500/6000], Loss: 0.3564\n",
      "Epoch [3/10], Step [4600/6000], Loss: 0.1561\n",
      "Epoch [3/10], Step [4700/6000], Loss: 0.6789\n",
      "Epoch [3/10], Step [4800/6000], Loss: 0.1419\n",
      "Epoch [3/10], Step [4900/6000], Loss: 0.1710\n",
      "Epoch [3/10], Step [5000/6000], Loss: 0.1207\n",
      "Epoch [3/10], Step [5100/6000], Loss: 0.0810\n",
      "Epoch [3/10], Step [5200/6000], Loss: 0.2243\n",
      "Epoch [3/10], Step [5300/6000], Loss: 0.3078\n",
      "Epoch [3/10], Step [5400/6000], Loss: 0.8000\n",
      "Epoch [3/10], Step [5500/6000], Loss: 0.2980\n",
      "Epoch [3/10], Step [5600/6000], Loss: 0.4350\n",
      "Epoch [3/10], Step [5700/6000], Loss: 0.4286\n",
      "Epoch [3/10], Step [5800/6000], Loss: 0.5430\n",
      "Epoch [3/10], Step [5900/6000], Loss: 0.2557\n",
      "Epoch [3/10], Step [6000/6000], Loss: 0.5056\n",
      "Epoch [4/10], Step [100/6000], Loss: 0.2519\n",
      "Epoch [4/10], Step [200/6000], Loss: 0.2555\n",
      "Epoch [4/10], Step [300/6000], Loss: 0.1067\n",
      "Epoch [4/10], Step [400/6000], Loss: 0.2258\n",
      "Epoch [4/10], Step [500/6000], Loss: 0.0874\n",
      "Epoch [4/10], Step [600/6000], Loss: 0.2665\n",
      "Epoch [4/10], Step [700/6000], Loss: 0.1559\n",
      "Epoch [4/10], Step [800/6000], Loss: 0.0692\n",
      "Epoch [4/10], Step [900/6000], Loss: 0.1270\n",
      "Epoch [4/10], Step [1000/6000], Loss: 0.3461\n",
      "Epoch [4/10], Step [1100/6000], Loss: 0.1383\n",
      "Epoch [4/10], Step [1200/6000], Loss: 0.2461\n",
      "Epoch [4/10], Step [1300/6000], Loss: 0.8744\n",
      "Epoch [4/10], Step [1400/6000], Loss: 0.2204\n",
      "Epoch [4/10], Step [1500/6000], Loss: 0.1900\n",
      "Epoch [4/10], Step [1600/6000], Loss: 0.2099\n",
      "Epoch [4/10], Step [1700/6000], Loss: 0.1657\n",
      "Epoch [4/10], Step [1800/6000], Loss: 0.1144\n",
      "Epoch [4/10], Step [1900/6000], Loss: 1.5031\n",
      "Epoch [4/10], Step [2000/6000], Loss: 0.1600\n",
      "Epoch [4/10], Step [2100/6000], Loss: 0.1942\n",
      "Epoch [4/10], Step [2200/6000], Loss: 0.1637\n",
      "Epoch [4/10], Step [2300/6000], Loss: 0.3775\n",
      "Epoch [4/10], Step [2400/6000], Loss: 0.1549\n",
      "Epoch [4/10], Step [2500/6000], Loss: 0.2811\n",
      "Epoch [4/10], Step [2600/6000], Loss: 0.4220\n",
      "Epoch [4/10], Step [2700/6000], Loss: 0.6215\n",
      "Epoch [4/10], Step [2800/6000], Loss: 0.4200\n",
      "Epoch [4/10], Step [2900/6000], Loss: 0.3176\n",
      "Epoch [4/10], Step [3000/6000], Loss: 0.1200\n",
      "Epoch [4/10], Step [3100/6000], Loss: 0.2726\n",
      "Epoch [4/10], Step [3200/6000], Loss: 0.4068\n",
      "Epoch [4/10], Step [3300/6000], Loss: 0.4843\n",
      "Epoch [4/10], Step [3400/6000], Loss: 0.0561\n",
      "Epoch [4/10], Step [3500/6000], Loss: 0.6385\n",
      "Epoch [4/10], Step [3600/6000], Loss: 0.1395\n",
      "Epoch [4/10], Step [3700/6000], Loss: 0.2366\n",
      "Epoch [4/10], Step [3800/6000], Loss: 0.1470\n",
      "Epoch [4/10], Step [3900/6000], Loss: 0.1019\n",
      "Epoch [4/10], Step [4000/6000], Loss: 0.2804\n",
      "Epoch [4/10], Step [4100/6000], Loss: 0.0838\n",
      "Epoch [4/10], Step [4200/6000], Loss: 0.3473\n",
      "Epoch [4/10], Step [4300/6000], Loss: 0.0456\n",
      "Epoch [4/10], Step [4400/6000], Loss: 0.1498\n",
      "Epoch [4/10], Step [4500/6000], Loss: 0.2794\n",
      "Epoch [4/10], Step [4600/6000], Loss: 0.2968\n",
      "Epoch [4/10], Step [4700/6000], Loss: 0.0930\n",
      "Epoch [4/10], Step [4800/6000], Loss: 0.3732\n",
      "Epoch [4/10], Step [4900/6000], Loss: 0.4413\n",
      "Epoch [4/10], Step [5000/6000], Loss: 0.7491\n",
      "Epoch [4/10], Step [5100/6000], Loss: 0.0507\n",
      "Epoch [4/10], Step [5200/6000], Loss: 0.3368\n",
      "Epoch [4/10], Step [5300/6000], Loss: 0.2115\n",
      "Epoch [4/10], Step [5400/6000], Loss: 0.1567\n",
      "Epoch [4/10], Step [5500/6000], Loss: 0.1583\n",
      "Epoch [4/10], Step [5600/6000], Loss: 0.2955\n",
      "Epoch [4/10], Step [5700/6000], Loss: 0.1754\n",
      "Epoch [4/10], Step [5800/6000], Loss: 0.3855\n",
      "Epoch [4/10], Step [5900/6000], Loss: 0.3612\n",
      "Epoch [4/10], Step [6000/6000], Loss: 0.1571\n",
      "Epoch [5/10], Step [100/6000], Loss: 0.2054\n",
      "Epoch [5/10], Step [200/6000], Loss: 0.4786\n",
      "Epoch [5/10], Step [300/6000], Loss: 0.3538\n",
      "Epoch [5/10], Step [400/6000], Loss: 0.1600\n",
      "Epoch [5/10], Step [500/6000], Loss: 0.1050\n",
      "Epoch [5/10], Step [600/6000], Loss: 0.2132\n",
      "Epoch [5/10], Step [700/6000], Loss: 1.0027\n",
      "Epoch [5/10], Step [800/6000], Loss: 0.1187\n",
      "Epoch [5/10], Step [900/6000], Loss: 0.3375\n",
      "Epoch [5/10], Step [1000/6000], Loss: 0.1302\n",
      "Epoch [5/10], Step [1100/6000], Loss: 0.4256\n",
      "Epoch [5/10], Step [1200/6000], Loss: 0.3208\n",
      "Epoch [5/10], Step [1300/6000], Loss: 0.1810\n",
      "Epoch [5/10], Step [1400/6000], Loss: 0.0809\n",
      "Epoch [5/10], Step [1500/6000], Loss: 0.8246\n",
      "Epoch [5/10], Step [1600/6000], Loss: 0.6418\n",
      "Epoch [5/10], Step [1700/6000], Loss: 0.3496\n",
      "Epoch [5/10], Step [1800/6000], Loss: 0.9220\n",
      "Epoch [5/10], Step [1900/6000], Loss: 0.2698\n",
      "Epoch [5/10], Step [2000/6000], Loss: 1.2186\n",
      "Epoch [5/10], Step [2100/6000], Loss: 0.3558\n",
      "Epoch [5/10], Step [2200/6000], Loss: 0.2649\n",
      "Epoch [5/10], Step [2300/6000], Loss: 0.3555\n",
      "Epoch [5/10], Step [2400/6000], Loss: 0.1589\n",
      "Epoch [5/10], Step [2500/6000], Loss: 0.3207\n",
      "Epoch [5/10], Step [2600/6000], Loss: 0.1271\n",
      "Epoch [5/10], Step [2700/6000], Loss: 0.3551\n",
      "Epoch [5/10], Step [2800/6000], Loss: 0.2066\n",
      "Epoch [5/10], Step [2900/6000], Loss: 0.5153\n",
      "Epoch [5/10], Step [3000/6000], Loss: 0.1885\n",
      "Epoch [5/10], Step [3100/6000], Loss: 0.1275\n",
      "Epoch [5/10], Step [3200/6000], Loss: 0.4133\n",
      "Epoch [5/10], Step [3300/6000], Loss: 0.1944\n",
      "Epoch [5/10], Step [3400/6000], Loss: 0.6011\n",
      "Epoch [5/10], Step [3500/6000], Loss: 0.0561\n",
      "Epoch [5/10], Step [3600/6000], Loss: 0.0883\n",
      "Epoch [5/10], Step [3700/6000], Loss: 0.4064\n",
      "Epoch [5/10], Step [3800/6000], Loss: 0.7225\n",
      "Epoch [5/10], Step [3900/6000], Loss: 0.1512\n",
      "Epoch [5/10], Step [4000/6000], Loss: 0.7968\n",
      "Epoch [5/10], Step [4100/6000], Loss: 0.6604\n",
      "Epoch [5/10], Step [4200/6000], Loss: 0.2537\n",
      "Epoch [5/10], Step [4300/6000], Loss: 0.3161\n",
      "Epoch [5/10], Step [4400/6000], Loss: 0.7242\n",
      "Epoch [5/10], Step [4500/6000], Loss: 0.2878\n",
      "Epoch [5/10], Step [4600/6000], Loss: 0.2742\n",
      "Epoch [5/10], Step [4700/6000], Loss: 0.5158\n",
      "Epoch [5/10], Step [4800/6000], Loss: 0.2562\n",
      "Epoch [5/10], Step [4900/6000], Loss: 0.4796\n",
      "Epoch [5/10], Step [5000/6000], Loss: 0.2993\n",
      "Epoch [5/10], Step [5100/6000], Loss: 0.4353\n",
      "Epoch [5/10], Step [5200/6000], Loss: 0.9896\n",
      "Epoch [5/10], Step [5300/6000], Loss: 0.0540\n",
      "Epoch [5/10], Step [5400/6000], Loss: 0.1841\n",
      "Epoch [5/10], Step [5500/6000], Loss: 0.5055\n",
      "Epoch [5/10], Step [5600/6000], Loss: 0.4368\n",
      "Epoch [5/10], Step [5700/6000], Loss: 0.0859\n",
      "Epoch [5/10], Step [5800/6000], Loss: 0.3397\n",
      "Epoch [5/10], Step [5900/6000], Loss: 0.9872\n",
      "Epoch [5/10], Step [6000/6000], Loss: 0.2581\n",
      "Epoch [6/10], Step [100/6000], Loss: 0.4383\n",
      "Epoch [6/10], Step [200/6000], Loss: 0.3864\n",
      "Epoch [6/10], Step [300/6000], Loss: 0.0770\n",
      "Epoch [6/10], Step [400/6000], Loss: 0.7173\n",
      "Epoch [6/10], Step [500/6000], Loss: 0.2962\n",
      "Epoch [6/10], Step [600/6000], Loss: 0.0494\n",
      "Epoch [6/10], Step [700/6000], Loss: 0.2296\n",
      "Epoch [6/10], Step [800/6000], Loss: 0.1045\n",
      "Epoch [6/10], Step [900/6000], Loss: 0.5953\n",
      "Epoch [6/10], Step [1000/6000], Loss: 0.3352\n",
      "Epoch [6/10], Step [1100/6000], Loss: 0.0521\n",
      "Epoch [6/10], Step [1200/6000], Loss: 0.5069\n",
      "Epoch [6/10], Step [1300/6000], Loss: 0.3118\n",
      "Epoch [6/10], Step [1400/6000], Loss: 0.6819\n",
      "Epoch [6/10], Step [1500/6000], Loss: 0.6938\n",
      "Epoch [6/10], Step [1600/6000], Loss: 0.2997\n",
      "Epoch [6/10], Step [1700/6000], Loss: 0.2914\n",
      "Epoch [6/10], Step [1800/6000], Loss: 0.0449\n",
      "Epoch [6/10], Step [1900/6000], Loss: 0.0910\n",
      "Epoch [6/10], Step [2000/6000], Loss: 0.3107\n",
      "Epoch [6/10], Step [2100/6000], Loss: 0.6862\n",
      "Epoch [6/10], Step [2200/6000], Loss: 0.1962\n",
      "Epoch [6/10], Step [2300/6000], Loss: 0.1215\n",
      "Epoch [6/10], Step [2400/6000], Loss: 0.0399\n",
      "Epoch [6/10], Step [2500/6000], Loss: 0.2380\n",
      "Epoch [6/10], Step [2600/6000], Loss: 0.6761\n",
      "Epoch [6/10], Step [2700/6000], Loss: 0.0774\n",
      "Epoch [6/10], Step [2800/6000], Loss: 0.1730\n",
      "Epoch [6/10], Step [2900/6000], Loss: 0.6469\n",
      "Epoch [6/10], Step [3000/6000], Loss: 0.0522\n",
      "Epoch [6/10], Step [3100/6000], Loss: 0.3545\n",
      "Epoch [6/10], Step [3200/6000], Loss: 0.3414\n",
      "Epoch [6/10], Step [3300/6000], Loss: 0.2019\n",
      "Epoch [6/10], Step [3400/6000], Loss: 0.0802\n",
      "Epoch [6/10], Step [3500/6000], Loss: 0.3032\n",
      "Epoch [6/10], Step [3600/6000], Loss: 0.1247\n",
      "Epoch [6/10], Step [3700/6000], Loss: 0.5100\n",
      "Epoch [6/10], Step [3800/6000], Loss: 0.0442\n",
      "Epoch [6/10], Step [3900/6000], Loss: 0.0949\n",
      "Epoch [6/10], Step [4000/6000], Loss: 0.1930\n",
      "Epoch [6/10], Step [4100/6000], Loss: 0.5237\n",
      "Epoch [6/10], Step [4200/6000], Loss: 0.2232\n",
      "Epoch [6/10], Step [4300/6000], Loss: 0.2855\n",
      "Epoch [6/10], Step [4400/6000], Loss: 0.5638\n",
      "Epoch [6/10], Step [4500/6000], Loss: 0.3393\n",
      "Epoch [6/10], Step [4600/6000], Loss: 0.0684\n",
      "Epoch [6/10], Step [4700/6000], Loss: 0.3708\n",
      "Epoch [6/10], Step [4800/6000], Loss: 0.0322\n",
      "Epoch [6/10], Step [4900/6000], Loss: 0.4163\n",
      "Epoch [6/10], Step [5000/6000], Loss: 0.1733\n",
      "Epoch [6/10], Step [5100/6000], Loss: 0.1229\n",
      "Epoch [6/10], Step [5200/6000], Loss: 0.0653\n",
      "Epoch [6/10], Step [5300/6000], Loss: 0.2921\n",
      "Epoch [6/10], Step [5400/6000], Loss: 0.5526\n",
      "Epoch [6/10], Step [5500/6000], Loss: 0.2276\n",
      "Epoch [6/10], Step [5600/6000], Loss: 0.0299\n",
      "Epoch [6/10], Step [5700/6000], Loss: 0.3686\n",
      "Epoch [6/10], Step [5800/6000], Loss: 0.0536\n",
      "Epoch [6/10], Step [5900/6000], Loss: 0.8881\n",
      "Epoch [6/10], Step [6000/6000], Loss: 0.3514\n",
      "Epoch [7/10], Step [100/6000], Loss: 0.7653\n",
      "Epoch [7/10], Step [200/6000], Loss: 0.0472\n",
      "Epoch [7/10], Step [300/6000], Loss: 0.4976\n",
      "Epoch [7/10], Step [400/6000], Loss: 0.3262\n",
      "Epoch [7/10], Step [500/6000], Loss: 0.2100\n",
      "Epoch [7/10], Step [600/6000], Loss: 0.1680\n",
      "Epoch [7/10], Step [700/6000], Loss: 0.3581\n",
      "Epoch [7/10], Step [800/6000], Loss: 0.1584\n",
      "Epoch [7/10], Step [900/6000], Loss: 0.0106\n",
      "Epoch [7/10], Step [1000/6000], Loss: 0.2486\n",
      "Epoch [7/10], Step [1100/6000], Loss: 0.4596\n",
      "Epoch [7/10], Step [1200/6000], Loss: 0.0654\n",
      "Epoch [7/10], Step [1300/6000], Loss: 0.0981\n",
      "Epoch [7/10], Step [1400/6000], Loss: 0.2614\n",
      "Epoch [7/10], Step [1500/6000], Loss: 0.3362\n",
      "Epoch [7/10], Step [1600/6000], Loss: 0.2758\n",
      "Epoch [7/10], Step [1700/6000], Loss: 0.0607\n",
      "Epoch [7/10], Step [1800/6000], Loss: 0.3702\n",
      "Epoch [7/10], Step [1900/6000], Loss: 0.1598\n",
      "Epoch [7/10], Step [2000/6000], Loss: 0.1678\n",
      "Epoch [7/10], Step [2100/6000], Loss: 0.2577\n",
      "Epoch [7/10], Step [2200/6000], Loss: 0.5214\n",
      "Epoch [7/10], Step [2300/6000], Loss: 0.3198\n",
      "Epoch [7/10], Step [2400/6000], Loss: 0.2196\n",
      "Epoch [7/10], Step [2500/6000], Loss: 0.4412\n",
      "Epoch [7/10], Step [2600/6000], Loss: 0.0364\n",
      "Epoch [7/10], Step [2700/6000], Loss: 0.1176\n",
      "Epoch [7/10], Step [2800/6000], Loss: 0.1838\n",
      "Epoch [7/10], Step [2900/6000], Loss: 0.4092\n",
      "Epoch [7/10], Step [3000/6000], Loss: 0.1898\n",
      "Epoch [7/10], Step [3100/6000], Loss: 0.5949\n",
      "Epoch [7/10], Step [3200/6000], Loss: 0.2052\n",
      "Epoch [7/10], Step [3300/6000], Loss: 0.1227\n",
      "Epoch [7/10], Step [3400/6000], Loss: 0.1309\n",
      "Epoch [7/10], Step [3500/6000], Loss: 0.2736\n",
      "Epoch [7/10], Step [3600/6000], Loss: 0.2207\n",
      "Epoch [7/10], Step [3700/6000], Loss: 0.3883\n",
      "Epoch [7/10], Step [3800/6000], Loss: 0.2087\n",
      "Epoch [7/10], Step [3900/6000], Loss: 0.2425\n",
      "Epoch [7/10], Step [4000/6000], Loss: 0.2257\n",
      "Epoch [7/10], Step [4100/6000], Loss: 0.2905\n",
      "Epoch [7/10], Step [4200/6000], Loss: 0.0389\n",
      "Epoch [7/10], Step [4300/6000], Loss: 0.1064\n",
      "Epoch [7/10], Step [4400/6000], Loss: 0.1365\n",
      "Epoch [7/10], Step [4500/6000], Loss: 0.2915\n",
      "Epoch [7/10], Step [4600/6000], Loss: 0.2503\n",
      "Epoch [7/10], Step [4700/6000], Loss: 0.0825\n",
      "Epoch [7/10], Step [4800/6000], Loss: 0.1527\n",
      "Epoch [7/10], Step [4900/6000], Loss: 0.2803\n",
      "Epoch [7/10], Step [5000/6000], Loss: 0.4216\n",
      "Epoch [7/10], Step [5100/6000], Loss: 0.0468\n",
      "Epoch [7/10], Step [5200/6000], Loss: 0.2077\n",
      "Epoch [7/10], Step [5300/6000], Loss: 0.1054\n",
      "Epoch [7/10], Step [5400/6000], Loss: 0.1841\n",
      "Epoch [7/10], Step [5500/6000], Loss: 0.3142\n",
      "Epoch [7/10], Step [5600/6000], Loss: 0.3106\n",
      "Epoch [7/10], Step [5700/6000], Loss: 0.0155\n",
      "Epoch [7/10], Step [5800/6000], Loss: 0.1194\n",
      "Epoch [7/10], Step [5900/6000], Loss: 0.2466\n",
      "Epoch [7/10], Step [6000/6000], Loss: 0.8155\n",
      "Epoch [8/10], Step [100/6000], Loss: 0.0565\n",
      "Epoch [8/10], Step [200/6000], Loss: 0.0515\n",
      "Epoch [8/10], Step [300/6000], Loss: 0.1720\n",
      "Epoch [8/10], Step [400/6000], Loss: 0.1210\n",
      "Epoch [8/10], Step [500/6000], Loss: 0.2792\n",
      "Epoch [8/10], Step [600/6000], Loss: 0.6482\n",
      "Epoch [8/10], Step [700/6000], Loss: 0.1748\n",
      "Epoch [8/10], Step [800/6000], Loss: 0.0881\n",
      "Epoch [8/10], Step [900/6000], Loss: 0.1007\n",
      "Epoch [8/10], Step [1000/6000], Loss: 0.4508\n",
      "Epoch [8/10], Step [1100/6000], Loss: 0.1300\n",
      "Epoch [8/10], Step [1200/6000], Loss: 0.1495\n",
      "Epoch [8/10], Step [1300/6000], Loss: 0.9663\n",
      "Epoch [8/10], Step [1400/6000], Loss: 0.1842\n",
      "Epoch [8/10], Step [1500/6000], Loss: 0.0611\n",
      "Epoch [8/10], Step [1600/6000], Loss: 0.4538\n",
      "Epoch [8/10], Step [1700/6000], Loss: 0.0355\n",
      "Epoch [8/10], Step [1800/6000], Loss: 0.1422\n",
      "Epoch [8/10], Step [1900/6000], Loss: 0.5689\n",
      "Epoch [8/10], Step [2000/6000], Loss: 0.1119\n",
      "Epoch [8/10], Step [2100/6000], Loss: 0.2127\n",
      "Epoch [8/10], Step [2200/6000], Loss: 0.2773\n",
      "Epoch [8/10], Step [2300/6000], Loss: 0.0316\n",
      "Epoch [8/10], Step [2400/6000], Loss: 0.1527\n",
      "Epoch [8/10], Step [2500/6000], Loss: 0.1159\n",
      "Epoch [8/10], Step [2600/6000], Loss: 0.3563\n",
      "Epoch [8/10], Step [2700/6000], Loss: 0.0936\n",
      "Epoch [8/10], Step [2800/6000], Loss: 0.1862\n",
      "Epoch [8/10], Step [2900/6000], Loss: 0.4254\n",
      "Epoch [8/10], Step [3000/6000], Loss: 0.4546\n",
      "Epoch [8/10], Step [3100/6000], Loss: 0.3939\n",
      "Epoch [8/10], Step [3200/6000], Loss: 0.1499\n",
      "Epoch [8/10], Step [3300/6000], Loss: 0.0590\n",
      "Epoch [8/10], Step [3400/6000], Loss: 0.0599\n",
      "Epoch [8/10], Step [3500/6000], Loss: 0.0107\n",
      "Epoch [8/10], Step [3600/6000], Loss: 0.1054\n",
      "Epoch [8/10], Step [3700/6000], Loss: 0.2014\n",
      "Epoch [8/10], Step [3800/6000], Loss: 0.0939\n",
      "Epoch [8/10], Step [3900/6000], Loss: 0.0755\n",
      "Epoch [8/10], Step [4000/6000], Loss: 0.3920\n",
      "Epoch [8/10], Step [4100/6000], Loss: 0.2081\n",
      "Epoch [8/10], Step [4200/6000], Loss: 0.3323\n",
      "Epoch [8/10], Step [4300/6000], Loss: 0.0406\n",
      "Epoch [8/10], Step [4400/6000], Loss: 0.1767\n",
      "Epoch [8/10], Step [4500/6000], Loss: 0.4686\n",
      "Epoch [8/10], Step [4600/6000], Loss: 0.5245\n",
      "Epoch [8/10], Step [4700/6000], Loss: 0.0487\n",
      "Epoch [8/10], Step [4800/6000], Loss: 0.0234\n",
      "Epoch [8/10], Step [4900/6000], Loss: 0.1031\n",
      "Epoch [8/10], Step [5000/6000], Loss: 0.2853\n",
      "Epoch [8/10], Step [5100/6000], Loss: 0.3691\n",
      "Epoch [8/10], Step [5200/6000], Loss: 0.5874\n",
      "Epoch [8/10], Step [5300/6000], Loss: 0.1230\n",
      "Epoch [8/10], Step [5400/6000], Loss: 0.1669\n",
      "Epoch [8/10], Step [5500/6000], Loss: 0.4148\n",
      "Epoch [8/10], Step [5600/6000], Loss: 0.8218\n",
      "Epoch [8/10], Step [5700/6000], Loss: 0.2062\n",
      "Epoch [8/10], Step [5800/6000], Loss: 0.6208\n",
      "Epoch [8/10], Step [5900/6000], Loss: 0.5094\n",
      "Epoch [8/10], Step [6000/6000], Loss: 0.2634\n",
      "Epoch [9/10], Step [100/6000], Loss: 0.3464\n",
      "Epoch [9/10], Step [200/6000], Loss: 0.1320\n",
      "Epoch [9/10], Step [300/6000], Loss: 0.0224\n",
      "Epoch [9/10], Step [400/6000], Loss: 0.3674\n",
      "Epoch [9/10], Step [500/6000], Loss: 0.0840\n",
      "Epoch [9/10], Step [600/6000], Loss: 0.3901\n",
      "Epoch [9/10], Step [700/6000], Loss: 0.2222\n",
      "Epoch [9/10], Step [800/6000], Loss: 0.1880\n",
      "Epoch [9/10], Step [900/6000], Loss: 0.1633\n",
      "Epoch [9/10], Step [1000/6000], Loss: 0.2382\n",
      "Epoch [9/10], Step [1100/6000], Loss: 0.2219\n",
      "Epoch [9/10], Step [1200/6000], Loss: 0.1838\n",
      "Epoch [9/10], Step [1300/6000], Loss: 0.4045\n",
      "Epoch [9/10], Step [1400/6000], Loss: 0.3134\n",
      "Epoch [9/10], Step [1500/6000], Loss: 0.0858\n",
      "Epoch [9/10], Step [1600/6000], Loss: 0.1523\n",
      "Epoch [9/10], Step [1700/6000], Loss: 0.3596\n",
      "Epoch [9/10], Step [1800/6000], Loss: 0.1086\n",
      "Epoch [9/10], Step [1900/6000], Loss: 0.8083\n",
      "Epoch [9/10], Step [2000/6000], Loss: 0.0741\n",
      "Epoch [9/10], Step [2100/6000], Loss: 0.4331\n",
      "Epoch [9/10], Step [2200/6000], Loss: 0.1130\n",
      "Epoch [9/10], Step [2300/6000], Loss: 0.0303\n",
      "Epoch [9/10], Step [2400/6000], Loss: 0.2058\n",
      "Epoch [9/10], Step [2500/6000], Loss: 0.0664\n",
      "Epoch [9/10], Step [2600/6000], Loss: 0.6765\n",
      "Epoch [9/10], Step [2700/6000], Loss: 0.5123\n",
      "Epoch [9/10], Step [2800/6000], Loss: 0.3682\n",
      "Epoch [9/10], Step [2900/6000], Loss: 0.1661\n",
      "Epoch [9/10], Step [3000/6000], Loss: 0.6526\n",
      "Epoch [9/10], Step [3100/6000], Loss: 0.0956\n",
      "Epoch [9/10], Step [3200/6000], Loss: 0.0622\n",
      "Epoch [9/10], Step [3300/6000], Loss: 0.1953\n",
      "Epoch [9/10], Step [3400/6000], Loss: 0.1898\n",
      "Epoch [9/10], Step [3500/6000], Loss: 0.0482\n",
      "Epoch [9/10], Step [3600/6000], Loss: 0.5985\n",
      "Epoch [9/10], Step [3700/6000], Loss: 0.0292\n",
      "Epoch [9/10], Step [3800/6000], Loss: 0.0987\n",
      "Epoch [9/10], Step [3900/6000], Loss: 0.1054\n",
      "Epoch [9/10], Step [4000/6000], Loss: 0.1219\n",
      "Epoch [9/10], Step [4100/6000], Loss: 0.3778\n",
      "Epoch [9/10], Step [4200/6000], Loss: 0.2352\n",
      "Epoch [9/10], Step [4300/6000], Loss: 0.2570\n",
      "Epoch [9/10], Step [4400/6000], Loss: 0.4104\n",
      "Epoch [9/10], Step [4500/6000], Loss: 0.4953\n",
      "Epoch [9/10], Step [4600/6000], Loss: 0.6583\n",
      "Epoch [9/10], Step [4700/6000], Loss: 0.0964\n",
      "Epoch [9/10], Step [4800/6000], Loss: 0.1626\n",
      "Epoch [9/10], Step [4900/6000], Loss: 0.1236\n",
      "Epoch [9/10], Step [5000/6000], Loss: 0.1856\n",
      "Epoch [9/10], Step [5100/6000], Loss: 0.1156\n",
      "Epoch [9/10], Step [5200/6000], Loss: 0.3473\n",
      "Epoch [9/10], Step [5300/6000], Loss: 0.2124\n",
      "Epoch [9/10], Step [5400/6000], Loss: 0.4018\n",
      "Epoch [9/10], Step [5500/6000], Loss: 0.0211\n",
      "Epoch [9/10], Step [5600/6000], Loss: 0.2204\n",
      "Epoch [9/10], Step [5700/6000], Loss: 0.0687\n",
      "Epoch [9/10], Step [5800/6000], Loss: 0.1132\n",
      "Epoch [9/10], Step [5900/6000], Loss: 0.1459\n",
      "Epoch [9/10], Step [6000/6000], Loss: 0.8774\n",
      "Epoch [10/10], Step [100/6000], Loss: 0.1870\n",
      "Epoch [10/10], Step [200/6000], Loss: 0.2335\n",
      "Epoch [10/10], Step [300/6000], Loss: 0.1904\n",
      "Epoch [10/10], Step [400/6000], Loss: 0.0231\n",
      "Epoch [10/10], Step [500/6000], Loss: 0.0522\n",
      "Epoch [10/10], Step [600/6000], Loss: 0.0794\n",
      "Epoch [10/10], Step [700/6000], Loss: 0.0873\n",
      "Epoch [10/10], Step [800/6000], Loss: 0.3099\n",
      "Epoch [10/10], Step [900/6000], Loss: 0.0429\n",
      "Epoch [10/10], Step [1000/6000], Loss: 0.3595\n",
      "Epoch [10/10], Step [1100/6000], Loss: 0.5341\n",
      "Epoch [10/10], Step [1200/6000], Loss: 0.3289\n",
      "Epoch [10/10], Step [1300/6000], Loss: 0.2741\n",
      "Epoch [10/10], Step [1400/6000], Loss: 0.1168\n",
      "Epoch [10/10], Step [1500/6000], Loss: 0.1293\n",
      "Epoch [10/10], Step [1600/6000], Loss: 0.1148\n",
      "Epoch [10/10], Step [1700/6000], Loss: 0.1545\n",
      "Epoch [10/10], Step [1800/6000], Loss: 0.1324\n",
      "Epoch [10/10], Step [1900/6000], Loss: 0.1421\n",
      "Epoch [10/10], Step [2000/6000], Loss: 0.1786\n",
      "Epoch [10/10], Step [2100/6000], Loss: 0.0118\n",
      "Epoch [10/10], Step [2200/6000], Loss: 0.6135\n",
      "Epoch [10/10], Step [2300/6000], Loss: 0.0945\n",
      "Epoch [10/10], Step [2400/6000], Loss: 0.0740\n",
      "Epoch [10/10], Step [2500/6000], Loss: 0.1175\n",
      "Epoch [10/10], Step [2600/6000], Loss: 0.1958\n",
      "Epoch [10/10], Step [2700/6000], Loss: 0.1511\n",
      "Epoch [10/10], Step [2800/6000], Loss: 0.1661\n",
      "Epoch [10/10], Step [2900/6000], Loss: 0.2835\n",
      "Epoch [10/10], Step [3000/6000], Loss: 0.0371\n",
      "Epoch [10/10], Step [3100/6000], Loss: 0.0744\n",
      "Epoch [10/10], Step [3200/6000], Loss: 0.0300\n",
      "Epoch [10/10], Step [3300/6000], Loss: 0.1601\n",
      "Epoch [10/10], Step [3400/6000], Loss: 0.5948\n",
      "Epoch [10/10], Step [3500/6000], Loss: 0.4176\n",
      "Epoch [10/10], Step [3600/6000], Loss: 0.1566\n",
      "Epoch [10/10], Step [3700/6000], Loss: 0.0332\n",
      "Epoch [10/10], Step [3800/6000], Loss: 0.5173\n",
      "Epoch [10/10], Step [3900/6000], Loss: 0.5337\n",
      "Epoch [10/10], Step [4000/6000], Loss: 0.0372\n",
      "Epoch [10/10], Step [4100/6000], Loss: 0.3772\n",
      "Epoch [10/10], Step [4200/6000], Loss: 0.0281\n",
      "Epoch [10/10], Step [4300/6000], Loss: 0.1202\n",
      "Epoch [10/10], Step [4400/6000], Loss: 0.0812\n",
      "Epoch [10/10], Step [4500/6000], Loss: 0.2168\n",
      "Epoch [10/10], Step [4600/6000], Loss: 0.3330\n",
      "Epoch [10/10], Step [4700/6000], Loss: 0.2664\n",
      "Epoch [10/10], Step [4800/6000], Loss: 0.5774\n",
      "Epoch [10/10], Step [4900/6000], Loss: 0.0892\n",
      "Epoch [10/10], Step [5000/6000], Loss: 0.2249\n",
      "Epoch [10/10], Step [5100/6000], Loss: 0.1257\n",
      "Epoch [10/10], Step [5200/6000], Loss: 0.1497\n",
      "Epoch [10/10], Step [5300/6000], Loss: 0.1788\n",
      "Epoch [10/10], Step [5400/6000], Loss: 0.2086\n",
      "Epoch [10/10], Step [5500/6000], Loss: 0.0181\n",
      "Epoch [10/10], Step [5600/6000], Loss: 0.1966\n",
      "Epoch [10/10], Step [5700/6000], Loss: 0.2710\n",
      "Epoch [10/10], Step [5800/6000], Loss: 0.1979\n",
      "Epoch [10/10], Step [5900/6000], Loss: 0.4344\n",
      "Epoch [10/10], Step [6000/6000], Loss: 0.0722\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (target, feature) in enumerate(train_dataloader):\n",
    "        target, feature = target.to(device), feature.to(device)\n",
    "        out = net(feature)\n",
    "#         out = out.reshape(-1)\n",
    "        target = target.reshape(-1)\n",
    "        criterion = loss(out, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        criterion.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, criterion.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "### 验证\n",
    "test_path = 'E:/data/FashionMNIST/FashionMNIST/processed/test.pt'\n",
    "# test_path = '/home/lor/Datasets/FashionMNIST/FashionMNIST/processed/test.pt'\n",
    "test_dataset = torch.load(test_path)\n",
    "print(test_dataset[0].shape)\n",
    "print(test_dataset[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_dataset[0], test_dataset[1])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.01%\n"
     ]
    }
   ],
   "source": [
    "total = 10000\n",
    "pred_count = 0\n",
    "for (target, feature) in test_dataloader:\n",
    "#     print(target.shape)\n",
    "#     print(feature.shape)\n",
    "    target = target.to(device)\n",
    "    feature = feature.to(device)\n",
    "    out = net(feature)\n",
    "#     print(torch.argmax(out, 1))\n",
    "#     print(target)\n",
    "#     print(torch.argmax(out, 1) == target)\n",
    "#     print((torch.argmax(out, 1) == target).sum().item())\n",
    "    pred_count = pred_count + (torch.argmax(out, 1) == target).sum().item()\n",
    "#     break\n",
    "print(\"Accuracy: {0}%\".format(100 * pred_count / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), './net.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "oth_net = Network()\n",
    "oth_net.load_state_dict(torch.load('./net.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1176, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oth_net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
